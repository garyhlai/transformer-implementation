{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer Implementation PyTorch Version.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMPvNMSMYL8FKnBzynIMlGJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghlai9665/transformer-implementation/blob/main/Transformer_Implementation_PyTorch_Version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHeQ8TyiMxrv"
      },
      "source": [
        "# Import Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pepx9GVRMmtZ",
        "outputId": "7ce28a7c-34be-4794-df1f-598c02830f36"
      },
      "source": [
        "!pip uninstall torchtext torch\n",
        "!pip install --pre torch torchtext -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html\n",
        "!pip install numpy matplotlib spacy seaborn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling torchtext-0.3.1:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/test/common/*\n",
            "    /usr/local/lib/python3.6/dist-packages/test/data/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torchtext-0.3.1.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torchtext/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torchtext-0.3.1\n",
            "Uninstalling torch-1.7.0+cu101:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/lib/python3.6/dist-packages/caffe2/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torch-1.7.0+cu101.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/*\n",
            "Proceed (y/n)? y\n",
            "y\n",
            "  Successfully uninstalled torch-1.7.0+cu101\n",
            "Looking in links: https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html\n",
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/nightly/cpu/torch-1.8.0.dev20210131%2Bcpu-cp36-cp36m-linux_x86_64.whl (167.7MB)\n",
            "\u001b[K     |████████████████████████████████| 167.7MB 93kB/s \n",
            "\u001b[?25hCollecting torchtext\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/nightly/torchtext-0.9.0.dev20210130-cp36-cp36m-linux_x86_64.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 56.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.10)\n",
            "\u001b[31mERROR: torchvision 0.8.1+cu101 has requirement torch==1.7.0, but you'll have torch 1.8.0.dev20210131+cpu which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.0.dev20210130 has requirement torch==1.8.0.dev20210130, but you'll have torch 1.8.0.dev20210131+cpu which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchtext\n",
            "Successfully installed torch-1.8.0.dev20210131+cpu torchtext-0.9.0.dev20210130\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.11.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (51.3.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIMgavMXoQMS"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "import math\n",
        "import time\n",
        "seaborn.set_context(context=\"talk\")\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iVyXGMbnik6",
        "outputId": "5980b611-66b9-48d3-dd62-7a22ea0039f3"
      },
      "source": [
        "!pip show torchtext"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: torchtext\n",
            "Version: 0.9.0.dev20210130\n",
            "Summary: Text utilities and datasets for PyTorch\n",
            "Home-page: https://github.com/pytorch/text\n",
            "Author: PyTorch core devs and James Bradbury\n",
            "Author-email: jekbradbury@gmail.com\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: tqdm, torch, requests, numpy\n",
            "Required-by: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fkl3l8c8Xj9N"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsBKs_h8M4Wd"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLZmVhxSM6qs",
        "outputId": "f05b5d36-3882-4abc-bd01-7e807b8150c4"
      },
      "source": [
        "!python -m spacy download en\n",
        "!python -m spacy download de"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (51.3.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (51.3.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907057 sha256=8a5438ac1c516e7cada576dec363438bc2c3f05715d3444a0eb3b1db35b4a199\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9gtlncdb/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eZbjBHxmgiD",
        "outputId": "3df99674-38c5-47ff-9f90-d4ae2eb401db"
      },
      "source": [
        "from torchtext.experimental.datasets import IWSLT\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "# tokenize the dataset (pairs of sentence strings -> pairs of arrays of indices)\n",
        "src_tokenizer = get_tokenizer(\"spacy\", language='de')\n",
        "tgt_tokenizer = get_tokenizer(\"spacy\", language='en')\n",
        "train_dataset, valid_dataset, test_dataset = IWSLT(tokenizer=(src_tokenizer, tgt_tokenizer))\n",
        "# vocab allows us see which index maps to which word\n",
        "de_vocab, en_vocab = train_dataset.get_vocab()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2016-01.tgz: 188MB [00:02, 67.2MB/s]\n",
            "100%|██████████| 196884/196884 [00:28<00:00, 6846.71lines/s]\n",
            "100%|██████████| 196884/196884 [00:19<00:00, 10250.79lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JOoGLcQyXry"
      },
      "source": [
        "class Batch:\n",
        "    def __init__(self, src, trg=None, pad_value=0):\n",
        "        src_vocab_size, trg_vocab_size = len(de_vocab.itos), len(en_vocab.itos)\n",
        "        # input src & trg are shape (batch_size, sentence_len) and embedded into (batch_size, sentence_len, d_model)\n",
        "        # finally transposed into (sentence_len, batch_size, d_model)\n",
        "        assert src.shape[0] == trg.shape[0], \"src and trg should have the same batch size!\"\n",
        "\n",
        "        batch_size, src_sentence_len = src.shape\n",
        "        # print(\"### trg.shape: \", trg.shape)\n",
        "\n",
        "        self.src_padding_mask = get_padding_mask(src)\n",
        "        self.src = embed(src, src_vocab_size).transpose(0, 1)\n",
        "        \n",
        "        if trg != None:\n",
        "            # given src & trg_x...\n",
        "            self.trg_padding_mask = get_padding_mask(trg[:,:-1])\n",
        "            trg_embedding = embed(trg, trg_vocab_size)\n",
        "            self.trg_x = trg_embedding[:, :-1, :].transpose(0, 1)\n",
        "            trg_sentence_len = self.trg_x.shape[0]\n",
        "            self.trg_attn_mask = generate_square_subsequent_mask(trg_sentence_len)\n",
        "            # ...we try to predict trg_y, which has ntokens words (i.e. we make ntokens predictions)\n",
        "            self.trg_y = trg[:, 1:].transpose(0,1)\n",
        "            self.ntokens = (self.trg_y != pad_value).sum()"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaanL0gCrYYQ"
      },
      "source": [
        "# this tells dataloader how you want your batch to look like \n",
        "# input is a list of tensors of size batch_size (dataloader just feeds you a mini-batch of batch_size at a time and you can process it),\n",
        "# where each tensor is [src, trg]\n",
        "# output is whatever you want in train_epoch\n",
        "def collate_batch(batch_data, pad_idx=1):\n",
        "    max_src_len = max([len(sentence_pair[0]) for sentence_pair in batch_data])\n",
        "    max_trg_len = max([len(sentence_pair[1]) for sentence_pair in batch_data])\n",
        "    # initialize the padding in the shape of the result src/trg we want\n",
        "    res_src = torch.zeros(len(batch_data), max_src_len).long() + pad_idx\n",
        "    res_trg = torch.zeros(len(batch_data), max_trg_len).long() + pad_idx\n",
        "    # layer the actual sentence on top of the padding\n",
        "    for i, sentence_pair in enumerate(batch_data):\n",
        "        src_sentence, trg_sentence = sentence_pair        \n",
        "        res_src[i, :len(src_sentence):], res_trg[i, :len(trg_sentence):] = src_sentence.long(), trg_sentence.long() # the first part of sentence are filled with words, the rest are pads\n",
        "        \n",
        "    return Batch(res_src, res_trg)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEDl_AIFO_WY"
      },
      "source": [
        "# divide the data into batches, using Dataloader\n",
        "sorted_train_dataset = sorted(train_dataset, key=lambda x: (len(x[0]), len(x[1])))\n",
        "# the output from a dataloader must be of shape u\n",
        "dataloader = DataLoader(sorted_train_dataset, batch_size=16, shuffle=False, collate_fn=lambda b: collate_batch(b))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AFmJA9ZqcRx"
      },
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "    return mask\n",
        "\n",
        "# input shape (N, S), you need to get src_padding_mask and trg_padding_mask\n",
        "def get_padding_mask(batch, pad_index = 1):\n",
        "    # batch_size, sentence_len = batch[1]\n",
        "    # shape (N, S)\n",
        "    padding_mask = (batch == pad_index)\n",
        "    return padding_mask"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUVA8sx5IuM3"
      },
      "source": [
        "# Explore Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuOK-F7nrEXq"
      },
      "source": [
        "def print_top(n_rows, mode='words'):\n",
        "  if mode == 'words':\n",
        "    for i in range(n_rows):\n",
        "      de_sentence = [de_vocab.itos[index] for index in train_dataset[i][0]]\n",
        "      en_sentence = [en_vocab.itos[index] for index in train_dataset[i][1]]\n",
        "      print((de_sentence, en_sentence))\n",
        "  elif mode == 'indices':\n",
        "    for i in range(n_rows):\n",
        "      print(train_dataset[i])\n",
        "\n",
        "print_top(100, 'words')\n",
        "print_top(10, 'indices')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzLl4qHUZ5oi",
        "outputId": "c7e10566-fc66-4bac-8c30-d81e29699e1f"
      },
      "source": [
        "print(de_vocab.stoi['<pad>'])\n",
        "print(en_vocab.stoi['<pad>'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gga9Cnulpm2E"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owu_2RAJmWG8"
      },
      "source": [
        "def embed(x, vocab_size, d_model=512):\n",
        "    # two embeddings (1) each token's numeral value is mapped to a embedding vector, index (scalar) -> embedding vector (size of d_model) \n",
        "    # (2) positional embedding is applied\n",
        "    number_to_embedding = nn.Embedding(vocab_size, d_model)\n",
        "    pos_embedding = PositionalEncoding(d_model)\n",
        "    x = number_to_embedding(x) * math.sqrt(d_model)\n",
        "    x = pos_embedding(x)\n",
        "    return x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya67Ak4qBV_1",
        "outputId": "75da1d5f-f362-4cb3-de28-91e369a94f79"
      },
      "source": [
        "for i, batch in enumerate(dataloader):\n",
        "    if i > 0:\n",
        "      break\n",
        "    print(\"## batch.src: \", batch.src.shape)\n",
        "    print(\"## batch.trg_x: \", batch.trg_x.shape)\n",
        "    print(\"## batch.trg_y: \", batch.trg_y.shape)\n",
        "    # print(\"## trg_attn_mask: \", batch.trg_attn_mask.shape, batch.trg_attn_mask)\n",
        "    print(\"## trg_padding_mask: \", batch.trg_padding_mask.shape, batch.trg_padding_mask)\n",
        "    print(\"## src_padding_mask: \", batch.src_padding_mask.shape, batch.src_padding_mask)\n",
        "\n",
        "\n",
        "    print(i)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## batch.src:  torch.Size([2, 16, 512])\n",
            "## batch.trg_x:  torch.Size([3, 16, 512])\n",
            "## batch.trg_y:  torch.Size([3, 16])\n",
            "## trg_padding_mask:  torch.Size([16, 3]) tensor([[False, False,  True],\n",
            "        [False, False,  True],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False]])\n",
            "## src_padding_mask:  torch.Size([16, 2]) tensor([[False, False],\n",
            "        [False, False],\n",
            "        [False, False],\n",
            "        [False, False],\n",
            "        [False, False],\n",
            "        [False, False],\n",
            "        [False, False],\n",
            "        [False, False],\n",
            "        [False, False],\n",
            "        [False, False],\n",
            "        [False, False],\n",
            "        [False, False],\n",
            "        [False, False],\n",
            "        [False, False],\n",
            "        [False, False],\n",
            "        [False, False]])\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmkDslslRG9d"
      },
      "source": [
        "# Define Functions for Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzF2dEyIokqS",
        "outputId": "1fdb1552-22cd-4ed0-87ad-ee390058bf1a"
      },
      "source": [
        "xtokens = 3\n",
        "a = torch.randn(xtokens, 16, 5); print(a.shape)\n",
        "b = a.view(-1, xtokens); print(b.shape)\n",
        "# [3, 16, 132937]\n",
        "# b = a.view(-1, 4); print(b.shape)\n",
        "# c = a.reshape(-1); print(c.shape)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 16, 5])\n",
            "torch.Size([80, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqSggciqFOpx"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, d_model, vocab):\n",
        "    super().__init__()\n",
        "    self.proj = nn.Linear(d_model, vocab) # define the linear projection, which takes d_model sized activation and output linear mapping to assign probability to each of the vocab\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return F.log_softmax(self.proj(x), dim=-1)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKQG-J7A8cIc"
      },
      "source": [
        "class Log:\n",
        "  def __init__(self):\n",
        "    self.start = time.time()\n",
        "    self.total_loss = 0\n",
        "    self.total_tokens = 0\n",
        "    # loss & tokens accumulated over the last < 50 steps\n",
        "    self.cur_loss = 0\n",
        "    self.cur_tokens = 0 \n",
        "\n",
        "  def batch_info(batch, loss):\n",
        "    self.total_loss += loss\n",
        "    self.total_tokens += int(batch.ntokens)\n",
        "    self.cur_loss += loss\n",
        "    self.cur_tokens += int(batch.ntokens)\n",
        "  \n",
        "  def reset_every_50batches():\n",
        "    self.cur_tokens = 0\n",
        "    self.cur_loss = 0\n",
        "    self.start = time.time()\n",
        "\n",
        "  def show_every_50batches(i):\n",
        "    elapsed = time.time() - self.start\n",
        "    print(\"-----\")\n",
        "    print(\"Epoch step: %d  Average Loss Per Token Over the Last 50 Batch: %f  Processed Tokens per Sec %f\" % (i, self.cur_loss / self.cur_tokens, self.cur_tokens / elapsed))\n",
        "    self.reset_every_50batches()\n",
        "\n",
        "  def show_epoch():\n",
        "    print(\"Total loss for the epoch is: \", total_loss / total_tokens)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNkxfdfpM7sk"
      },
      "source": [
        "# Every epoch is an iteration over the entire training set (how many steps are in one epoch depends on the batch_size)\n",
        "def train_epoch(data, model, hyper_params):\n",
        "  model.encoder_decoder.train() \n",
        "  # varialbes for logging\n",
        "  log = Log()\n",
        "  # train the model batch-by-batch \n",
        "  for i, batch in enumerate(data):\n",
        "    batch_loss = train_batch(batch, model, hyper_params)\n",
        "    log.batch_info(batch, batch_loss)\n",
        "    if i % 50 == 1:\n",
        "      log.show_every_50batches(i)\n",
        "  log.show_epoch()\n",
        "  scheduler.step()"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6d6Hmq8us2r"
      },
      "source": [
        "def train_batch(batch, model, hyper_params):\n",
        "    def forward_pass():\n",
        "        src = batch.src.to(device=device)\n",
        "        trg_x = batch.trg_x.to(device=device)\n",
        "        src_padding_mask = batch.src_padding_mask.to(device=device)\n",
        "        trg_attn_mask = batch.trg_attn_mask.to(device=device)\n",
        "        trg_padding_mask = batch.trg_padding_mask.to(device=device)\n",
        "        \n",
        "        pred = model.forward(src, trg_x, src_padding_mask, trg_attn_mask, trg_padding_mask).view(-1, len(de_vocab.stoi))\n",
        "        return pred\n",
        "    \n",
        "    def calculate_loss(prediction):\n",
        "        trg_y = batch.trg_y.to(device=device).reshape(-1)\n",
        "        print(\"## pred.shape: \", pred.shape)\n",
        "        print(\"## trg_y.shape: \", trg_y.shape)\n",
        "        loss = hyper_params.criterion(pred, trg_y)  \n",
        "        return loss\n",
        "\n",
        "    pred = forward_pass()\n",
        "    loss = calculate_loss(pred)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    return float(loss)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbCwFnc3RyaC"
      },
      "source": [
        "# Define Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPgDxnghvbnp"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, encoder_decoder, generator):\n",
        "    super().__init__()\n",
        "    self.encoder_decoder = encoder_decoder\n",
        "    self.generator = generator\n",
        "\n",
        "  def forward(self, src, trg_x, src_key_padding_mask, tgt_mask, tgt_key_padding_mask):\n",
        "    out = self.encoder_decoder.forward(src, trg_x, src_key_padding_mask = src_key_padding_mask, tgt_mask = tgt_mask, tgt_key_padding_mask =  tgt_key_padding_mask)\n",
        "    out = self.generator.forward(out)\n",
        "    return out"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ahlMIsq3w_x"
      },
      "source": [
        "class HyperParams():\n",
        "  def __init__(self, criterion = None, optimizer = None, scheduler = None):\n",
        "    self.criterion, self.optimizer, self.scheduler = criterion, optimizer, scheduler"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISH_SUwtR4M1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec12469-d739-402d-9b67-35c508086d22"
      },
      "source": [
        "# variables\n",
        "pad_value = de_vocab.stoi['<pad>']; print(\"## pad_value: \", pad_value)\n",
        "d_model = 512\n",
        "lr = 5.0 \n",
        "tgt_vocab_size = len(de_vocab.itos)\n",
        "\n",
        "# initialize model\n",
        "encoder_decoder = nn.Transformer().to(device)\n",
        "generator = Generator(d_model, tgt_vocab_size).to(device)\n",
        "model = Model(encoder_decoder, generator)\n",
        "\n",
        "# hyper_params = MyHyperParams(criterion = nn.CrossEntropyLoss(), optimizer = torch.optim.Adam(model.parameters(), lr=lr), scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95))\n",
        "# hyper_params = HyperParams(criterion = nn.CrossEntropyLoss(), optimizer = torch.optim.Adam(model.parameters(), lr=lr))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.encoder_decoder.parameters(), lr=lr) \n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "hyper_params = HyperParams(criterion=criterion, optimizer=optimizer, scheduler=scheduler)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## pad_value:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa_5YRemRLqN"
      },
      "source": [
        "# Start Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-q-vJvaQ4yc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91b0acf5-42f0-489d-dea5-d03f32730a5b"
      },
      "source": [
        "# train for 10 epochs\n",
        "for epoch in range(1):\n",
        "  print(\"------------Training epoch \", epoch, \"--------------\")\n",
        "  train_epoch(dataloader, model, hyper_params)\n",
        "  # set to eval model to check how good the model is after each loop\n",
        "  # print(train_epoch((batchify(b, pad_idx, device) for b in valid_iterator), model, criterion, epoch))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------Training epoch  0 --------------\n",
            "## pred.shape:  torch.Size([48, 132937])\n",
            "## trg_y.shape:  torch.Size([48])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}