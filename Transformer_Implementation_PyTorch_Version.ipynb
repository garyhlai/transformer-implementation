{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer Implementation PyTorch Version.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNz4vZPozPS50RgDzYLB9Dh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghlai9665/transformer-implementation/blob/main/Transformer_Implementation_PyTorch_Version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHeQ8TyiMxrv"
      },
      "source": [
        "# Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pepx9GVRMmtZ",
        "outputId": "4c88d47a-3808-4da4-8926-5a7ef4b80e16"
      },
      "source": [
        "!pip install torch numpy matplotlib spacy torchtext==0.4.0 seaborn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Collecting torchtext==0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.11.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.1.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed torchtext-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWFUU6F8NKrv"
      },
      "source": [
        "# import dependencies\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "import time\n",
        "seaborn.set_context(context=\"talk\")\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkl3l8c8Xj9N",
        "outputId": "7b99fb31-6bde-4175-b16e-8a2476d2e326"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsBKs_h8M4Wd"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om0aSUg-8k9n"
      },
      "source": [
        "??torch.add"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLZmVhxSM6qs",
        "outputId": "e0c08755-cfbb-4cbb-e876-2a58735d3672"
      },
      "source": [
        "!python -m spacy download en\n",
        "!python -m spacy download de"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 709kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907056 sha256=b5aeed4aad98f0784de5545f40dca0e1aa6074442ec4379b328fb756847e1c64\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-huucwbi_/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTwyH6z3Orlt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71a517ac-adbc-47fd-eb8f-fc12d08b866b"
      },
      "source": [
        "from torchtext.datasets import IWSLT\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "# define the tokenizers and params for the data (i don't think Spacy does subword tokenization)\n",
        "SRC = Field(tokenize = \"spacy\",\n",
        "            tokenizer_language = \"de\",\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            lower = True)\n",
        "TRG = Field(tokenize = \"spacy\",\n",
        "            tokenizer_language=\"en\",\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            lower = True)\n",
        "\n",
        "# split data into train, validate, and test group, all are torch.data.Dataset objects\n",
        "train_data, valid_data, test_data = IWSLT.splits(exts = ('.de', '.en'),\n",
        "                                                 fields = (SRC, TRG))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading de-en.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "de-en.tgz: 100%|██████████| 24.2M/24.2M [00:11<00:00, 2.04MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".data/iwslt/de-en/IWSLT16.TED.tst2011.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2014.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.dev2010.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2013.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2014.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2013.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2012.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2014.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2010.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.dev2012.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.dev2010.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2014.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2013.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2013.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2011.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2010.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2012.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.dev2012.de-en.de.xml\n",
            ".data/iwslt/de-en/train.tags.de-en.en\n",
            ".data/iwslt/de-en/train.tags.de-en.de\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVvnLgMFjYsS"
      },
      "source": [
        "import torchtext\n",
        "import math"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "FQir-4H4aQAn",
        "outputId": "c4c6daee-37e8-45fd-fe9a-9c3b747d69d1"
      },
      "source": [
        "print(type(train_data))\n",
        "print(isinstance(train_data, torchtext.data.Example)) \n",
        "print(isinstance(train_data, torchtext.data.Dataset)) \n",
        "print(\"IWSLT type: \", type(IWSLT))\n",
        "print(isinstance(IWSLT, torchtext.data.Dataset)) \n",
        "print(train_data[0])\n",
        "print(isinstance(train_data[0], torchtext.data.Example)) \n",
        "print(train_data[0].__dict__.keys())\n",
        "print(train_data[0].src)\n",
        "print(train_data[0].trg)\n",
        "print(train_data[1].trg)\n",
        "\n",
        "'''\n",
        "From the print statements, you can see that train_data is a `torchtext.data.Dataset` object, which is a \"list\" containing many\n",
        "`torchtext.data.example.Example` objects!\n",
        "'''"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torchtext.datasets.translation.IWSLT\n",
            "False\n",
            "True\n",
            "IWSLT type:  <class 'typing.GenericMeta'>\n",
            "False\n",
            "<torchtext.data.example.Example object at 0x7f110171fbe0>\n",
            "True\n",
            "dict_keys(['src', 'trg'])\n",
            "['david', 'gallo', ':', 'das', 'ist', 'bill', 'lange', '.', 'ich', 'bin', 'dave', 'gallo', '.']\n",
            "['david', 'gallo', ':', 'this', 'is', 'bill', 'lange', '.', 'i', \"'m\", 'dave', 'gallo', '.']\n",
            "['and', 'we', \"'re\", 'going', 'to', 'tell', 'you', 'some', 'stories', 'from', 'the', 'sea', 'here', 'in', 'video', '.']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nFrom the print statements, you can see that train_data is a `torchtext.data.Dataset` object, which is a \"list\" containing many\\n`torchtext.data.example.Example` objects!\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDNHWOMnk7tP",
        "outputId": "9c859a81-11d6-4155-cc42-ff1fe284f385"
      },
      "source": [
        "print(\"len(train_data): \", len(train_data))\n",
        "print(\"get item: \", train_data[1])\n",
        "print(\"get item: \", train_data.__getitem__(1))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(train_data):  196884\n",
            "get item:  <torchtext.data.example.Example object at 0x7f110171feb8>\n",
            "get item:  <torchtext.data.example.Example object at 0x7f110171feb8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY4gwzd7O5hr"
      },
      "source": [
        "# build a vocabulary to index words with numbers; you can go from word to number via SRC.vocab.stoi\n",
        "# Batch objects contains references to Dataset objects which itself contains references to Field objects. \n",
        "# When Batch is initialized, it calls Field.process which calls Field.numericalize which calls self.vocab -- if you don't build the vocab here, you will get an error when Batch is initialized later\n",
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sno60PsOPJY1",
        "outputId": "a74cc1e7-b287-4383-d895-10809cab704b"
      },
      "source": [
        "BATCH_SIZE = 4\n",
        "# BucketIterator batches sentences of similar lengths together to minimize padding\n",
        "split_result = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE)\n",
        "print(split_result)\n",
        "print(type(split_result))\n",
        "# One BucketIterator for each dataset\n",
        "train_iterator, valid_iterator, test_iterator = split_result"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<torchtext.data.iterator.BucketIterator object at 0x7f10dc9221d0>, <torchtext.data.iterator.BucketIterator object at 0x7f10dc9228d0>, <torchtext.data.iterator.BucketIterator object at 0x7f10dc922978>)\n",
            "<class 'tuple'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO06jMuYXupA",
        "outputId": "3d911ac4-1690-48e2-edfd-bd54fb0a3bf8"
      },
      "source": [
        "print(train_iterator.dataset[0].src)\n",
        "print(train_iterator)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['david', 'gallo', ':', 'das', 'ist', 'bill', 'lange', '.', 'ich', 'bin', 'dave', 'gallo', '.']\n",
            "<torchtext.data.iterator.BucketIterator object at 0x7f10dc9221d0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DnTijBLPeM7"
      },
      "source": [
        "# size of the source vocab\n",
        "src_vocab_size = len(SRC.vocab.itos)\n",
        "tgt_vocab_size = len(TRG.vocab.itos)\n",
        "# print(src_vocab_size)\n",
        "# print(tgt_vocab_size)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0ep2q1oDG-e"
      },
      "source": [
        "# translate batch.srcs or batch.nums to sentence form\n",
        "def batch_nums_to_sentences(nums, src):\n",
        "  nums_transposed = nums.transpose(0,1)\n",
        "  m, n = nums_transposed.shape\n",
        "  # print(\"The transposed shape is: \", m, \" * \", n)\n",
        "  batch_tokens = [[None for _ in range(n)] for _ in range(m)]\n",
        "  for i in range(m):\n",
        "    for j in range(n):\n",
        "      batch_tokens[i][j] = SRC.vocab.itos[nums_transposed[i][j]] if src else TRG.vocab.itos[nums_transposed[i][j]]\n",
        "\n",
        "  batch_sentences = [\" \".join(row) for row in batch_tokens]\n",
        "  # print(\"there are \", len(batch_sentences), \" sentences in the batch.\")\n",
        "\n",
        "  return batch_sentences\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wgm0bPpzhSn"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPuUpQy1cNTg",
        "outputId": "872f81e1-6cf2-45cb-90bf-70fc10940257"
      },
      "source": [
        "counter = 0\n",
        "for i, batch in enumerate(train_iterator):\n",
        "\n",
        "  if counter > 2:\n",
        "    break\n",
        "  src, trg = batch.src.to(device=device), batch.trg.to(device=device)\n",
        "  print(\"batch.src.device: \", batch.src.device)\n",
        "  print(\"src.device: \", src.device)\n",
        "  print(\"batch.trg.device: \", batch.trg.device)\n",
        "  print(\"trg.device: \", trg.device)\n",
        "  \n",
        "  # # ***** the size of torch.data.batch.src/trg is (sentence length, batch_size) ****\n",
        "  # print(batch.trg.shape)\n",
        "  # print(batch_nums_to_sentences(batch.trg, False))\n",
        "  # print(batch_nums_to_sentences(batch.src, True))\n",
        "\n",
        "  counter += 1"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch.src.device:  cpu\n",
            "src.device:  cuda:0\n",
            "batch.trg.device:  cpu\n",
            "trg.device:  cuda:0\n",
            "batch.src.device:  cpu\n",
            "src.device:  cuda:0\n",
            "batch.trg.device:  cpu\n",
            "trg.device:  cuda:0\n",
            "batch.src.device:  cpu\n",
            "src.device:  cuda:0\n",
            "batch.trg.device:  cpu\n",
            "trg.device:  cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmkDslslRG9d"
      },
      "source": [
        "# Define Functions for Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owu_2RAJmWG8"
      },
      "source": [
        "def embed(x, vocab_size, d_model=512):\n",
        "  # two embedding (1) each token's numeral value is mapped to a embedding vector (2) positional embedding is applied\n",
        "  number_to_embedding = nn.Embedding(vocab_size, d_model)\n",
        "  pos_embedding = PositionalEncoding(d_model)\n",
        "\n",
        "  x = number_to_embedding(x) * math.sqrt(d_model)\n",
        "  x = pos_embedding(x)\n",
        "  return x"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JOoGLcQyXry"
      },
      "source": [
        "class Batch:\n",
        "  def __init__(self, src, trg=None, pad_value=0):\n",
        "    # input src & trg are shape (sentence_len, batch_size) and embedded into (sentence_len, batch_size, d_model)\n",
        "    self.src = embed(src, src_vocab_size)\n",
        "    if trg != None:\n",
        "      # given src & trg_x, we try to predict trg_y, which has ntokens words (i.e. we make ntokens predictions)\n",
        "      trg_embedding = embed(trg, tgt_vocab_size)\n",
        "      self.trg_x = trg_embedding[:-1, :, :]\n",
        "      self._trg_y = trg[1:, :]\n",
        "      self.trg_y = _trg_y.reshape(-1)\n",
        "      self.ntokens = (_trg_y != pad_value).sum()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gga9Cnulpm2E"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqSggciqFOpx"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, d_model, vocab):\n",
        "    super().__init__()\n",
        "    self.proj = nn.Linear(d_model, vocab) # define the linear projection, which takes d_model sized activation and output linear mapping to assign probability to each of the vocab\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return F.log_softmax(self.proj(x), dim=-1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKQG-J7A8cIc"
      },
      "source": [
        "class Log:\n",
        "  def __init__(self):\n",
        "    self.start = time.time()\n",
        "    self.total_loss = 0\n",
        "    self.total_tokens = 0\n",
        "    # loss & tokens accumulated over the last < 50 steps\n",
        "    self.cur_loss = 0\n",
        "    self.cur_tokens = 0 \n",
        "\n",
        "  def batch_info(batch, loss):\n",
        "    self.total_loss += loss\n",
        "    self.total_tokens += int(batch.ntokens)\n",
        "    self.cur_loss += loss\n",
        "    self.cur_tokens += int(batch.ntokens)\n",
        "  \n",
        "  def reset_every_50batches():\n",
        "    self.cur_tokens = 0\n",
        "    self.cur_loss = 0\n",
        "    self.start = time.time()\n",
        "\n",
        "  def show_every_50batches(i):\n",
        "    elapsed = time.time() - self.start\n",
        "    print(\"-----\")\n",
        "    print(\"Epoch step: %d  Average Loss Per Token Over the Last 50 Batch: %f  Processed Tokens per Sec %f\" % (i, self.cur_loss / self.cur_tokens, self.cur_tokens / elapsed))\n",
        "    self.reset_every_50batches()\n",
        "\n",
        "  def show_epoch():\n",
        "    print(\"Total loss for the epoch is: \", total_loss / total_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNkxfdfpM7sk"
      },
      "source": [
        "# Every epoch is an iteration over the entire training set (how many steps are in one epoch depends on the batch_size)\n",
        "def train_epoch(data, model, hyper_params):\n",
        "  model.train() \n",
        "  # varialbes for logging\n",
        "  log = Log()\n",
        "  # train the model batch-by-batch \n",
        "  for i, batch in enumerate(data):\n",
        "    batch_loss = train_batch(batch, model, hyper_params)\n",
        "    log.batch_info(batch, batch_loss)\n",
        "    if i % 50 == 1:\n",
        "      log.show_every_50batches(i)\n",
        "  log.show_epoch()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6d6Hmq8us2r"
      },
      "source": [
        "def train_batch(batch, model, hyper_params):\n",
        "    def forward_pass():\n",
        "      src = batch.src.to(device=device)\n",
        "      trg_x = batch.trg_x.to(device=device)\n",
        "      pred = model(src, trg_x)\n",
        "      return pred\n",
        "    \n",
        "    def calculate_loss(pred):\n",
        "      trg_y = batch.trg_y.to(device=device)\n",
        "      loss = hyper_params.criterion(pred.view(-1,tgt_vocab_size), trg_y)  \n",
        "      return loss\n",
        "\n",
        "    pred = foward_pass()\n",
        "    loss = calculate_loss(pred)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    return float(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbCwFnc3RyaC"
      },
      "source": [
        "# Define Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPgDxnghvbnp"
      },
      "source": [
        "class Model:\n",
        "  def __init__(self, encoder_decoder, generator):\n",
        "    self.encoder_decoer = encoder_decoder\n",
        "    self.generator = generator\n",
        "\n",
        "  def forward(src, trg_x):\n",
        "    out = self.encoder_decoder.foward(src, trg_x)\n",
        "    out = self.generator.forward(out)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ahlMIsq3w_x"
      },
      "source": [
        "class HyperParams:\n",
        "  def __init__(self, criterion = None, optimizer = None, scheduler = None):\n",
        "    self.criterion, self.optimizer, self.scheduler = criterion, optimizer, scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISH_SUwtR4M1"
      },
      "source": [
        "# variables\n",
        "pad_value = TRG.vocab.stoi['<pad>']\n",
        "d_model = 512\n",
        "lr = 5.0 \n",
        "\n",
        "# initialize the training params\n",
        "data = (Batch(batch.src, batch.trg, pad_value) for batch in train_iterator)\n",
        "\n",
        "# initialize model\n",
        "encoder_decoder = nn.Transformer().to(device)\n",
        "generator = Generator(d_model, tgt_vocab_size).to(device)\n",
        "model = Model(encoder_decoder, generator)\n",
        "\n",
        "hyper_params = HyperParams(criterion = nn.CrossEntropyLoss(), optimizer = torch.optim.SGD(model.parameters(), lr=lr), scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa_5YRemRLqN"
      },
      "source": [
        "# Start Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-q-vJvaQ4yc"
      },
      "source": [
        "# train for 10 epochs\n",
        "for epoch in range(1):\n",
        "  print(\"------------Training epoch \", epoch, \"--------------\")\n",
        "  train_epoch(data, model, hyper_params)\n",
        "  scheduler.step()\n",
        "  # set to eval model to check how good the model is after each loop\n",
        "  # print(train_epoch((batchify(b, pad_idx, device) for b in valid_iterator), model, criterion, epoch))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}